{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/javie/Desktop/CVC\")\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "import time\n",
    "\n",
    "from utils.slices import *\n",
    "from utils.orientaciones import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, pkl_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.pkl_dir = pkl_dir\n",
    "\n",
    "        self.classes = os.listdir(data_dir)\n",
    "        self.mesh_info = []\n",
    "        self.labels = []\n",
    "        self.n = 0\n",
    "        for class_index, class_path in enumerate(self.classes):\n",
    "            # Create directory if does not exist\n",
    "            os.makedirs(pkl_dir + class_path, exist_ok=True)\n",
    "            mesh_paths = os.listdir(data_dir + class_path)\n",
    "            for path in mesh_paths:\n",
    "                pkl_path = pkl_dir + class_path + '/' + path + '.pkl'\n",
    "                if os.path.exists(pkl_path):\n",
    "                    with open(pkl_path, 'rb') as archivo:\n",
    "                        pkl_object = pickle.load(archivo)\n",
    "                    #self.classes.append(pkl_object[0])\n",
    "                    self.mesh_info.append(pkl_object[1])\n",
    "                    self.labels.append(pkl_object[2]) #index of self.classes\n",
    "                else:\n",
    "                    mesh = trimesh.load(data_dir + class_path + '/' + path)\n",
    "                    descriptors_list = sample_slices(mesh)\n",
    "                    \n",
    "                    self.mesh_info.append(descriptors_list)\n",
    "                    self.labels.append(class_index)\n",
    "                    with open(pkl_path, 'wb') as archivo:\n",
    "                        pickle.dump([class_path, descriptors_list, class_index], archivo)\n",
    "\n",
    "        #self.classes = torch.tensor(self.classes)\n",
    "        self.mesh_info = torch.tensor(self.mesh_info)\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.mesh_info[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../data/oriented_dataset/\"\n",
    "pkl_path = \"../data/descriptors_dataset/\"\n",
    "dataset = CustomImageDataset(dataset_path, pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ROW / 6ROW adjustment\n",
    "dataset.labels[dataset.labels == 0] = 0  # Dundee 2ROW British\n",
    "dataset.labels[dataset.labels == 1] = 0  # Dundee 2ROW Scottish\n",
    "dataset.labels[dataset.labels == 2] = 1  # Dundee 6ROW BERE Orkney\n",
    "dataset.labels[dataset.labels == 3] = 1  # Dundee 6ROW BERE Unknown\n",
    "dataset.labels[dataset.labels == 4] = 1  # Dundee 6ROW BERE Western Isles\n",
    "dataset.labels[dataset.labels == 5] = 1  # Dundee 6ROW Faro\n",
    "dataset.labels[dataset.labels == 6] = 1  # Dundee 6ROW Scandinavian\n",
    "dataset.labels[dataset.labels == 7] = 0  # Orkney 2ROW British\n",
    "dataset.labels[dataset.labels == 8] = 0  # Orkney 2ROW Scottish\n",
    "dataset.labels[dataset.labels == 9] = 1  # Orkney 6ROW BERE Orkney\n",
    "dataset.labels[dataset.labels == 10] = 1  # Orkney 6ROW BERE Unknown\n",
    "dataset.labels[dataset.labels == 11] = 1  # Orkney 6ROW BERE Western Isles\n",
    "dataset.labels[dataset.labels == 12] = 1  # Orkney 6ROW Scandinavian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 904])\n",
      "Shape of y: torch.Size([16]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([8, 904])\n",
      "Shape of y: torch.Size([8]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrainClassifier(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=904, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (13): ReLU()\n",
      "  )\n",
      "  (classification_layer): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "'''\n",
    "# Define model\n",
    "class GrainClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(904, 512, dtype=torch.double),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, dtype=torch.double),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, dtype=torch.double),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, dtype=torch.double),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, dtype=torch.double),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, dtype=torch.double),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512, dtype=torch.double),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classification_layer = nn.Linear(512, 2, dtype=torch.double)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = self.classification_layer(x)\n",
    "        return x\n",
    "\n",
    "'''model = GrainClassifier().to(device)\n",
    "print(model)'''\n",
    "\n",
    "model = GrainClassifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    X = torch.rand(10, 124, device=device)\\n    X *= -1\\n    logits = model(X)\\n    pred_probab = nn.Softmax(dim=1)(logits)\\n    y_pred = pred_probab.argmax(1)\\n    print(f\"Input: {X}\")\\n    print(f\"Prob class: {pred_probab}\")\\n    print(f\"Predicted class: {y_pred}\")'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    X = torch.rand(10, 124, device=device)\n",
    "    X *= -1\n",
    "    logits = model(X)\n",
    "    pred_probab = nn.Softmax(dim=1)(logits)\n",
    "    y_pred = pred_probab.argmax(1)\n",
    "    print(f\"Input: {X}\")\n",
    "    print(f\"Prob class: {pred_probab}\")\n",
    "    print(f\"Predicted class: {y_pred}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader):\n",
    "    running_loss = 0.\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "        '''print(\"outputs\")\n",
    "        print(outputs)\n",
    "        print(\"labels\")\n",
    "        print(labels)\n",
    "        '''# Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    #print(\"Total loss: \", running_loss)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataloader):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)  # Número total de ejemplos\n",
    "\n",
    "    # Calcula la precisión como el número de predicciones correctas dividido por el total\n",
    "    accuracy = correct / total\n",
    "        \n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX ACCURACY\n",
      "Epoch: 0  , train loss: 21.501395584761813, test loss: 9.710076731458464 , accuracy: 0.5238095238095238\n",
      "MAX ACCURACY\n",
      "Epoch: 10 , train loss: 21.47677484612678, test loss: 9.69555431878521 , accuracy: 0.5666666666666667\n",
      "MAX ACCURACY\n",
      "Epoch: 11 , train loss: 21.473978127812227, test loss: 9.695334261975205 , accuracy: 0.6476190476190476\n",
      "Epoch: 20 , train loss: 21.461593773390437, test loss: 9.687719520686619 , accuracy: 0.49047619047619045\n",
      "Epoch: 30 , train loss: 21.44743816505955, test loss: 9.678232645563773 , accuracy: 0.49047619047619045\n",
      "MAX ACCURACY\n",
      "Epoch: 37 , train loss: 21.422110421959257, test loss: 9.670639692082972 , accuracy: 0.6666666666666666\n",
      "Epoch: 40 , train loss: 21.43238292867368, test loss: 9.665525432244698 , accuracy: 0.5904761904761905\n",
      "MAX ACCURACY\n",
      "Epoch: 49 , train loss: 21.373167872315417, test loss: 9.645904294937885 , accuracy: 0.6714285714285714\n",
      "Epoch: 50 , train loss: 21.371692183806626, test loss: 9.642976308666904 , accuracy: 0.6476190476190476\n",
      "MAX ACCURACY\n",
      "Epoch: 60 , train loss: 21.294015159300642, test loss: 9.602620121419307 , accuracy: 0.680952380952381\n",
      "Epoch: 70 , train loss: 21.13077349267807, test loss: 9.515942191170089 , accuracy: 0.6761904761904762\n",
      "MAX ACCURACY\n",
      "Epoch: 73 , train loss: 21.040441006448894, test loss: 9.467937561411738 , accuracy: 0.6952380952380952\n",
      "Epoch: 80 , train loss: 20.65896735737976, test loss: 9.286946580041695 , accuracy: 0.6904761904761905\n",
      "MAX ACCURACY\n",
      "Epoch: 83 , train loss: 20.40924326589133, test loss: 9.178704517189606 , accuracy: 0.7\n",
      "Epoch: 90 , train loss: 20.177461797185128, test loss: 8.936365149031838 , accuracy: 0.6476190476190476\n",
      "MAX ACCURACY\n",
      "Epoch: 95 , train loss: 19.72513380618562, test loss: 8.662481866776792 , accuracy: 0.7047619047619048\n",
      "Epoch: 100, train loss: 18.905343239161166, test loss: 8.890200093296313 , accuracy: 0.6476190476190476\n",
      "MAX ACCURACY\n",
      "Epoch: 101, train loss: 19.250768390117738, test loss: 8.511115361944096 , accuracy: 0.7142857142857143\n",
      "MAX ACCURACY\n",
      "Epoch: 103, train loss: 18.71068385274389, test loss: 8.45566265742277 , accuracy: 0.7428571428571429\n",
      "Epoch: 110, train loss: 18.82491101894527, test loss: 8.37860533498106 , accuracy: 0.7380952380952381\n",
      "MAX ACCURACY\n",
      "Epoch: 117, train loss: 17.44965697347317, test loss: 7.9565621839763985 , accuracy: 0.7571428571428571\n",
      "MAX ACCURACY\n",
      "Epoch: 118, train loss: 18.046621022679776, test loss: 7.877366183112391 , accuracy: 0.7619047619047619\n",
      "MAX ACCURACY\n",
      "Epoch: 119, train loss: 18.31528054248646, test loss: 7.793944993171054 , accuracy: 0.7714285714285715\n",
      "Epoch: 120, train loss: 17.758729966462557, test loss: 8.21724828420869 , accuracy: 0.719047619047619\n",
      "MAX ACCURACY\n",
      "Epoch: 121, train loss: 18.176244498862083, test loss: 7.7894472289910786 , accuracy: 0.7761904761904762\n",
      "MAX ACCURACY\n",
      "Epoch: 123, train loss: 16.97301452128802, test loss: 7.519750565731391 , accuracy: 0.8\n",
      "Epoch: 130, train loss: 15.557412942050664, test loss: 7.48783787485111 , accuracy: 0.7047619047619048\n",
      "MAX ACCURACY\n",
      "Epoch: 131, train loss: 15.065494593448324, test loss: 6.92209370855149 , accuracy: 0.8095238095238095\n",
      "Epoch: 140, train loss: 14.461541076082689, test loss: 6.7943528728314 , accuracy: 0.7571428571428571\n",
      "MAX ACCURACY\n",
      "Epoch: 143, train loss: 15.112589765948588, test loss: 6.998185770946193 , accuracy: 0.8142857142857143\n",
      "MAX ACCURACY\n",
      "Epoch: 146, train loss: 14.988045785996746, test loss: 6.441247425748214 , accuracy: 0.819047619047619\n",
      "Epoch: 150, train loss: 15.090887992336432, test loss: 10.798753606883446 , accuracy: 0.5761904761904761\n",
      "MAX ACCURACY\n",
      "Epoch: 152, train loss: 14.7299666266425, test loss: 6.899237336881601 , accuracy: 0.8238095238095238\n",
      "Epoch: 160, train loss: 13.645229414281532, test loss: 7.447223067984698 , accuracy: 0.7238095238095238\n",
      "MAX ACCURACY\n",
      "Epoch: 164, train loss: 12.783230810404756, test loss: 6.140470287963345 , accuracy: 0.8285714285714286\n",
      "MAX ACCURACY\n",
      "Epoch: 167, train loss: 13.619887306833254, test loss: 5.880712962192891 , accuracy: 0.8333333333333334\n",
      "Epoch: 170, train loss: 15.496616706266536, test loss: 6.628457380325187 , accuracy: 0.8333333333333334\n",
      "MAX ACCURACY\n",
      "Epoch: 176, train loss: 14.780759298497683, test loss: 5.741965014520724 , accuracy: 0.8380952380952381\n",
      "MAX ACCURACY\n",
      "Epoch: 177, train loss: 13.77073794247878, test loss: 5.81018103703398 , accuracy: 0.8523809523809524\n",
      "MAX ACCURACY\n",
      "Epoch: 178, train loss: 11.482979454336842, test loss: 5.75562145784445 , accuracy: 0.8571428571428571\n",
      "MAX ACCURACY\n",
      "Epoch: 180, train loss: 11.124806525727193, test loss: 5.182036702479277 , accuracy: 0.861904761904762\n",
      "Epoch: 190, train loss: 12.862078779230478, test loss: 7.5432246203905455 , accuracy: 0.7904761904761904\n",
      "Epoch: 200, train loss: 11.22735822986599, test loss: 12.207870446353263 , accuracy: 0.6285714285714286\n",
      "Epoch: 210, train loss: 15.231953107600338, test loss: 8.606669555321083 , accuracy: 0.7142857142857143\n",
      "MAX ACCURACY\n",
      "Epoch: 215, train loss: 13.581088176538952, test loss: 5.3894870827300565 , accuracy: 0.8666666666666667\n",
      "Epoch: 220, train loss: 11.619342837500243, test loss: 5.864051289665365 , accuracy: 0.8571428571428571\n",
      "MAX ACCURACY\n",
      "Epoch: 221, train loss: 11.566292430461942, test loss: 5.352287945284854 , accuracy: 0.8714285714285714\n",
      "Epoch: 230, train loss: 10.77086640839212, test loss: 5.1862702675144075 , accuracy: 0.8571428571428571\n",
      "Epoch: 240, train loss: 9.73231605892407, test loss: 7.824112360750409 , accuracy: 0.7904761904761904\n",
      "Epoch: 250, train loss: 13.225630381002777, test loss: 5.508651530082477 , accuracy: 0.8523809523809524\n",
      "Epoch: 260, train loss: 14.092414064807937, test loss: 5.585771678802277 , accuracy: 0.8476190476190476\n",
      "Epoch: 270, train loss: 13.604763099933399, test loss: 5.776835507731514 , accuracy: 0.8428571428571429\n",
      "MAX ACCURACY\n",
      "Epoch: 275, train loss: 12.333146937712257, test loss: 5.104338359387318 , accuracy: 0.8761904761904762\n",
      "Epoch: 280, train loss: 11.218219702528302, test loss: 5.477131067600024 , accuracy: 0.8666666666666667\n",
      "MAX ACCURACY\n",
      "Epoch: 283, train loss: 9.594308680447648, test loss: 4.751041178174542 , accuracy: 0.8809523809523809\n",
      "Epoch: 290, train loss: 10.939685031535362, test loss: 11.945486985151941 , accuracy: 0.6428571428571429\n",
      "Epoch: 300, train loss: 14.479213426142298, test loss: 5.764141907050766 , accuracy: 0.8333333333333334\n",
      "Epoch: 310, train loss: 13.874025199799654, test loss: 5.717870452821618 , accuracy: 0.8571428571428571\n",
      "Epoch: 320, train loss: 12.562311731791981, test loss: 5.780073784895137 , accuracy: 0.8238095238095238\n",
      "Epoch: 330, train loss: 15.061938589826442, test loss: 7.997094400334216 , accuracy: 0.6428571428571429\n",
      "MAX ACCURACY\n",
      "Epoch: 338, train loss: 9.786088406224497, test loss: 4.782791490147746 , accuracy: 0.8857142857142857\n",
      "Epoch: 340, train loss: 14.33227117655419, test loss: 7.80365630082388 , accuracy: 0.719047619047619\n",
      "MAX ACCURACY\n",
      "Epoch: 347, train loss: 9.729118023952177, test loss: 4.67080875842254 , accuracy: 0.8904761904761904\n",
      "Epoch: 350, train loss: 9.140578477491465, test loss: 4.68138056674239 , accuracy: 0.8904761904761904\n",
      "Epoch: 360, train loss: 17.408257215809908, test loss: 7.226283619761403 , accuracy: 0.8333333333333334\n",
      "Epoch: 370, train loss: 14.674700427474182, test loss: 5.815445320158394 , accuracy: 0.8333333333333334\n",
      "Epoch: 380, train loss: 12.31581944162763, test loss: 5.948527364727097 , accuracy: 0.8571428571428571\n",
      "Epoch: 390, train loss: 10.520258793514326, test loss: 5.331683305616259 , accuracy: 0.8809523809523809\n",
      "Epoch: 400, train loss: 13.893817130425257, test loss: 5.869032456219813 , accuracy: 0.8476190476190476\n",
      "Epoch: 410, train loss: 11.447656957823414, test loss: 5.6744945613449245 , accuracy: 0.861904761904762\n",
      "Epoch: 420, train loss: 18.277774580401463, test loss: 7.285086539055813 , accuracy: 0.7761904761904762\n",
      "Epoch: 430, train loss: 16.135059358093145, test loss: 5.664781739689198 , accuracy: 0.8428571428571429\n",
      "Epoch: 440, train loss: 14.985349518166093, test loss: 7.09829549315026 , accuracy: 0.7857142857142857\n",
      "Epoch: 450, train loss: 11.656307756285916, test loss: 4.66550502180922 , accuracy: 0.8904761904761904\n",
      "Epoch: 460, train loss: 10.025584118448599, test loss: 6.156793410683912 , accuracy: 0.8476190476190476\n",
      "MAX ACCURACY\n",
      "Epoch: 461, train loss: 12.715039867624425, test loss: 4.753360991235278 , accuracy: 0.8952380952380953\n",
      "Epoch: 470, train loss: 15.348791593447475, test loss: 8.715157005499105 , accuracy: 0.7333333333333333\n",
      "MAX ACCURACY\n",
      "Epoch: 478, train loss: 9.063757153676828, test loss: 4.4934065406696355 , accuracy: 0.9\n",
      "Epoch: 480, train loss: 8.456650412496813, test loss: 5.904494926957444 , accuracy: 0.8571428571428571\n",
      "MAX ACCURACY\n",
      "Epoch: 488, train loss: 7.911839574466816, test loss: 4.409112419285846 , accuracy: 0.9047619047619048\n",
      "Epoch: 490, train loss: 14.180866639797703, test loss: 4.5419512497601175 , accuracy: 0.8952380952380953\n",
      "Epoch: 500, train loss: 10.11719313370189, test loss: 6.250648750050198 , accuracy: 0.8476190476190476\n",
      "MAX ACCURACY\n",
      "Epoch: 509, train loss: 11.430932210260488, test loss: 3.9946096768126056 , accuracy: 0.9095238095238095\n",
      "Epoch: 510, train loss: 8.329276526963664, test loss: 6.701741130616168 , accuracy: 0.7666666666666667\n",
      "Epoch: 520, train loss: 8.923239211404587, test loss: 5.108136542492517 , accuracy: 0.8761904761904762\n",
      "MAX ACCURACY\n",
      "Epoch: 522, train loss: 6.797923685017512, test loss: 3.8269505817421896 , accuracy: 0.9142857142857143\n",
      "Epoch: 530, train loss: 7.105742902183974, test loss: 4.604568331914588 , accuracy: 0.8809523809523809\n",
      "Epoch: 540, train loss: 7.563993792753849, test loss: 5.465587881449137 , accuracy: 0.8333333333333334\n",
      "Epoch: 550, train loss: 6.394891704105424, test loss: 4.31343511282124 , accuracy: 0.9047619047619048\n",
      "MAX ACCURACY\n",
      "Epoch: 551, train loss: 7.365109853778434, test loss: 3.683693330421642 , accuracy: 0.9238095238095239\n",
      "Epoch: 560, train loss: 6.232481704249986, test loss: 4.526878031984864 , accuracy: 0.8952380952380953\n",
      "Epoch: 570, train loss: 6.335866516097103, test loss: 6.995949441714139 , accuracy: 0.8333333333333334\n",
      "Epoch: 580, train loss: 8.70766160337541, test loss: 9.678295037018458 , accuracy: 0.6619047619047619\n",
      "Epoch: 590, train loss: 6.737130686011313, test loss: 3.7477882767930146 , accuracy: 0.9238095238095239\n",
      "MAX ACCURACY\n",
      "Epoch: 593, train loss: 7.150526356697552, test loss: 3.944512818793976 , accuracy: 0.9285714285714286\n",
      "Epoch: 600, train loss: 8.472545005487133, test loss: 11.895916666339163 , accuracy: 0.7047619047619048\n",
      "Epoch: 610, train loss: 5.901322268152066, test loss: 3.767645831775386 , accuracy: 0.9285714285714286\n",
      "MAX ACCURACY\n",
      "Epoch: 611, train loss: 5.026554823931272, test loss: 3.596096124163297 , accuracy: 0.9333333333333333\n",
      "Epoch: 620, train loss: 8.024281185368109, test loss: 7.826376651352084 , accuracy: 0.7428571428571429\n",
      "Epoch: 630, train loss: 8.859882456242007, test loss: 7.87820210435773 , accuracy: 0.7952380952380952\n",
      "Epoch: 640, train loss: 5.885182065065864, test loss: 6.154128697198233 , accuracy: 0.8333333333333334\n",
      "Epoch: 650, train loss: 9.84791878192044, test loss: 6.523753792453367 , accuracy: 0.7666666666666667\n",
      "MAX ACCURACY\n",
      "Epoch: 659, train loss: 6.75106802957718, test loss: 3.546825247511178 , accuracy: 0.9380952380952381\n",
      "Epoch: 660, train loss: 6.785685205428787, test loss: 3.545384642234631 , accuracy: 0.9380952380952381\n",
      "Epoch: 670, train loss: 4.942901395334682, test loss: 4.047538656317736 , accuracy: 0.9047619047619048\n",
      "Epoch: 680, train loss: 6.157412598890479, test loss: 4.769280772432251 , accuracy: 0.8666666666666667\n",
      "Epoch: 690, train loss: 4.833338438040834, test loss: 7.0396796825286465 , accuracy: 0.8285714285714286\n",
      "Epoch: 700, train loss: 9.566348811055176, test loss: 3.9371810362910757 , accuracy: 0.9\n",
      "Epoch: 710, train loss: 12.364748283070753, test loss: 10.431179439314285 , accuracy: 0.6904761904761905\n",
      "Epoch: 720, train loss: 6.604563880744787, test loss: 4.563520927269455 , accuracy: 0.8904761904761904\n",
      "Epoch: 730, train loss: 6.299193003688582, test loss: 4.005397797523211 , accuracy: 0.919047619047619\n",
      "Epoch: 740, train loss: 5.285845388529989, test loss: 5.51080966465599 , accuracy: 0.8476190476190476\n",
      "Epoch: 750, train loss: 16.841308557678044, test loss: 14.867563957748063 , accuracy: 0.6238095238095238\n",
      "Epoch: 760, train loss: 8.93761810119251, test loss: 8.87022342873761 , accuracy: 0.8047619047619048\n",
      "Epoch: 770, train loss: 7.7725509695541355, test loss: 3.7723459234032646 , accuracy: 0.9285714285714286\n",
      "Epoch: 780, train loss: 5.875982779855787, test loss: 3.6926655895189864 , accuracy: 0.9333333333333333\n",
      "Epoch: 790, train loss: 4.8567215083120665, test loss: 4.715302661453959 , accuracy: 0.8904761904761904\n",
      "Epoch: 800, train loss: 6.964158840720801, test loss: 5.593496220629476 , accuracy: 0.861904761904762\n",
      "MAX ACCURACY\n",
      "Epoch: 807, train loss: 8.853798882337944, test loss: 3.702941426060356 , accuracy: 0.9428571428571428\n",
      "Epoch: 810, train loss: 4.694763940323065, test loss: 3.6142056357644536 , accuracy: 0.9333333333333333\n",
      "Epoch: 820, train loss: 4.838655762969454, test loss: 5.399630110321849 , accuracy: 0.8380952380952381\n",
      "Epoch: 830, train loss: 4.649608487318001, test loss: 3.605362250631232 , accuracy: 0.9333333333333333\n",
      "Epoch: 840, train loss: 6.147474729886493, test loss: 4.387069687186133 , accuracy: 0.8761904761904762\n",
      "Epoch: 850, train loss: 3.776406538178933, test loss: 3.7135427335024183 , accuracy: 0.9333333333333333\n",
      "Epoch: 860, train loss: 5.444334769445978, test loss: 3.7445681692616173 , accuracy: 0.9380952380952381\n",
      "Epoch: 870, train loss: 4.731402460923009, test loss: 4.236024152681296 , accuracy: 0.9095238095238095\n",
      "Epoch: 880, train loss: 4.646064911220169, test loss: 9.413720211526504 , accuracy: 0.8047619047619048\n",
      "Epoch: 890, train loss: 3.2355174217091895, test loss: 3.85295666057469 , accuracy: 0.9285714285714286\n",
      "Epoch: 900, train loss: 4.533717826052989, test loss: 3.776399979528671 , accuracy: 0.9285714285714286\n",
      "Epoch: 910, train loss: 3.883119118230425, test loss: 5.886473066888302 , accuracy: 0.8571428571428571\n",
      "Epoch: 920, train loss: 5.324928539071929, test loss: 3.627498075791894 , accuracy: 0.9333333333333333\n",
      "Epoch: 930, train loss: 14.603995205130524, test loss: 4.046350688385715 , accuracy: 0.9285714285714286\n",
      "MAX ACCURACY\n",
      "Epoch: 937, train loss: 3.8967195708626337, test loss: 3.645508580224945 , accuracy: 0.9476190476190476\n",
      "Epoch: 940, train loss: 4.53173027987572, test loss: 3.7673235165177674 , accuracy: 0.9380952380952381\n",
      "Epoch: 950, train loss: 4.083360463995129, test loss: 3.8906322632494077 , accuracy: 0.9333333333333333\n",
      "Epoch: 960, train loss: 22.264584570215714, test loss: 5.953761510781012 , accuracy: 0.7857142857142857\n",
      "Epoch: 970, train loss: 3.814949174364127, test loss: 3.6851167410214285 , accuracy: 0.9333333333333333\n",
      "Epoch: 980, train loss: 3.975599871996236, test loss: 4.169818854591823 , accuracy: 0.9238095238095239\n",
      "Epoch: 990, train loss: 3.580775521530203, test loss: 4.1121268517832865 , accuracy: 0.9285714285714286\n",
      "0.9476190476190476\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../models/old_school\"\n",
    "max_accuracy = 0\n",
    "for i in range(1000):\n",
    "    train_loss = train_one_epoch(train_loader)\n",
    "    test_loss, accuracy = test_model(test_loader)\n",
    "    if max_accuracy < accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        print(\"MAX ACCURACY\")\n",
    "        print(\"Epoch: \" + \"%-3i\" % i + \", train loss: \" + str(train_loss) + \", test loss: \" + str(test_loss), \", accuracy: \" + str(accuracy))\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        continue\n",
    "    if i % 10 == 0:\n",
    "        print(\"Epoch: \" + \"%-3i\" % i + \", train loss: \" + str(train_loss) + \", test loss: \" + str(test_loss), \", accuracy: \" + str(accuracy))\n",
    "print(max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load(\"../data/oriented_dataset/Orkney 2ROW British/OHBT16104 7L10.stl\")\n",
    "descriptors_list = sample_slices(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 904])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.tensor(descriptors_list).unsqueeze(0)\n",
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs = tensor([[ 1.7967, -1.6297]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "predictions = tensor([0])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inp)\n",
    "print(f\"outputs = {outputs}\")\n",
    "_, predictions = torch.max(outputs.data, 1)\n",
    "print(f\"predictions = {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cebada_old_school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
